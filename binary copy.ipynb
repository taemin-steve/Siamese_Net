{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EHmin\\anaconda3\\envs\\EHmin\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import glob\n",
    "import cv2 as cv\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from tqdm.auto import tqdm\n",
    "import timm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_model_summary\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make DataFrame\n",
    "\n",
    "## columns: review_img_path, product_img_path, label\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./masked_data/product_img\\\\0.jpg', './masked_data/product_img\\\\1.jpg', './masked_data/product_img\\\\10.jpg', './masked_data/product_img\\\\100.jpg', './masked_data/product_img\\\\12.jpg', './masked_data/product_img\\\\13.jpg', './masked_data/product_img\\\\14.jpg', './masked_data/product_img\\\\15.jpg', './masked_data/product_img\\\\20.jpg', './masked_data/product_img\\\\25.jpg', './masked_data/product_img\\\\28.jpg', './masked_data/product_img\\\\30.jpg', './masked_data/product_img\\\\33.jpg', './masked_data/product_img\\\\34.jpg', './masked_data/product_img\\\\35.jpg', './masked_data/product_img\\\\36.jpg', './masked_data/product_img\\\\37.jpg', './masked_data/product_img\\\\39.jpg', './masked_data/product_img\\\\4.jpg', './masked_data/product_img\\\\40.jpg', './masked_data/product_img\\\\41.jpg', './masked_data/product_img\\\\42.jpg', './masked_data/product_img\\\\43.jpg', './masked_data/product_img\\\\45.jpg', './masked_data/product_img\\\\46.jpg', './masked_data/product_img\\\\48.jpg', './masked_data/product_img\\\\49.jpg', './masked_data/product_img\\\\5.jpg', './masked_data/product_img\\\\50.jpg', './masked_data/product_img\\\\52.jpg', './masked_data/product_img\\\\53.jpg', './masked_data/product_img\\\\54.jpg', './masked_data/product_img\\\\59.jpg', './masked_data/product_img\\\\60.jpg', './masked_data/product_img\\\\61.jpg', './masked_data/product_img\\\\62.jpg', './masked_data/product_img\\\\63.jpg', './masked_data/product_img\\\\66.jpg', './masked_data/product_img\\\\68.jpg', './masked_data/product_img\\\\7.jpg', './masked_data/product_img\\\\73.jpg', './masked_data/product_img\\\\74.jpg', './masked_data/product_img\\\\77.jpg', './masked_data/product_img\\\\78.jpg', './masked_data/product_img\\\\79.jpg', './masked_data/product_img\\\\80.jpg', './masked_data/product_img\\\\82.jpg', './masked_data/product_img\\\\83.jpg', './masked_data/product_img\\\\84.jpg', './masked_data/product_img\\\\87.jpg', './masked_data/product_img\\\\88.jpg', './masked_data/product_img\\\\90.jpg', './masked_data/product_img\\\\92.jpg', './masked_data/product_img\\\\94.jpg', './masked_data/product_img\\\\96.jpg', './masked_data/product_img\\\\98.jpg']\n"
     ]
    }
   ],
   "source": [
    "all_product_img_list = glob.glob('./masked_data/product_img/*')\n",
    "all_product_img_list = sorted(all_product_img_list)\n",
    "print(all_product_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_img_path = []\n",
    "product_img_path = []\n",
    "label = []\n",
    "for product_img in all_product_img_list:\n",
    "    glob_img_list = []\n",
    "    str = product_img.split(\"\\\\\")[1] # for window\n",
    "    # str = product_img.split(\"/\")[3] # for linux\n",
    "    \n",
    "    str = str.split(\".\")[0]\n",
    "    glob_img_list = glob.glob('./masked_data/review_img/'+str +'_review_img/O/*.jpg')\n",
    "    review_img_path = review_img_path + glob_img_list\n",
    "    product_img_path = product_img_path + [product_img  for i in range(len(glob_img_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18749\n",
      "18749\n"
     ]
    }
   ],
   "source": [
    "print(len(product_img_path))\n",
    "print(len(review_img_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(review_img_path)):\n",
    "    random_number = random.randint(0, 1)\n",
    "    if random_number == 0:\n",
    "        label.append(0)\n",
    "    else:\n",
    "        review_num = review_img_path[i].split('\\\\')[1] # for Window \n",
    "        # review_num = review_img_path[i].split('/')[3] # for Linux\n",
    "        \n",
    "        review_num = review_num.split(\"_\")[0]\n",
    "        random_number = random.randint(0, len(all_product_img_list) - 1)\n",
    "        while review_num == random_number:\n",
    "            random_number = random.randint(0, len(all_product_img_list) - 1)\n",
    "        product_img_path[i] = all_product_img_list[random_number]\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_img_path</th>\n",
       "      <th>product_img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./masked_data/review_img/0_review_img/O\\1.jpg</td>\n",
       "      <td>./masked_data/product_img\\0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./masked_data/review_img/0_review_img/O\\107.jpg</td>\n",
       "      <td>./masked_data/product_img\\20.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./masked_data/review_img/0_review_img/O\\109.jpg</td>\n",
       "      <td>./masked_data/product_img\\0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./masked_data/review_img/0_review_img/O\\111.jpg</td>\n",
       "      <td>./masked_data/product_img\\0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./masked_data/review_img/0_review_img/O\\119.jpg</td>\n",
       "      <td>./masked_data/product_img\\0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18744</th>\n",
       "      <td>./masked_data/review_img/98_review_img/O\\93.jpg</td>\n",
       "      <td>./masked_data/product_img\\68.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18745</th>\n",
       "      <td>./masked_data/review_img/98_review_img/O\\95.jpg</td>\n",
       "      <td>./masked_data/product_img\\98.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18746</th>\n",
       "      <td>./masked_data/review_img/98_review_img/O\\96.jpg</td>\n",
       "      <td>./masked_data/product_img\\98.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18747</th>\n",
       "      <td>./masked_data/review_img/98_review_img/O\\97.jpg</td>\n",
       "      <td>./masked_data/product_img\\37.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18748</th>\n",
       "      <td>./masked_data/review_img/98_review_img/O\\98.jpg</td>\n",
       "      <td>./masked_data/product_img\\98.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18749 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       review_img_path   \n",
       "0        ./masked_data/review_img/0_review_img/O\\1.jpg  \\\n",
       "1      ./masked_data/review_img/0_review_img/O\\107.jpg   \n",
       "2      ./masked_data/review_img/0_review_img/O\\109.jpg   \n",
       "3      ./masked_data/review_img/0_review_img/O\\111.jpg   \n",
       "4      ./masked_data/review_img/0_review_img/O\\119.jpg   \n",
       "...                                                ...   \n",
       "18744  ./masked_data/review_img/98_review_img/O\\93.jpg   \n",
       "18745  ./masked_data/review_img/98_review_img/O\\95.jpg   \n",
       "18746  ./masked_data/review_img/98_review_img/O\\96.jpg   \n",
       "18747  ./masked_data/review_img/98_review_img/O\\97.jpg   \n",
       "18748  ./masked_data/review_img/98_review_img/O\\98.jpg   \n",
       "\n",
       "                       product_img_path  label  \n",
       "0       ./masked_data/product_img\\0.jpg      0  \n",
       "1      ./masked_data/product_img\\20.jpg      1  \n",
       "2       ./masked_data/product_img\\0.jpg      0  \n",
       "3       ./masked_data/product_img\\0.jpg      0  \n",
       "4       ./masked_data/product_img\\0.jpg      0  \n",
       "...                                 ...    ...  \n",
       "18744  ./masked_data/product_img\\68.jpg      1  \n",
       "18745  ./masked_data/product_img\\98.jpg      0  \n",
       "18746  ./masked_data/product_img\\98.jpg      0  \n",
       "18747  ./masked_data/product_img\\37.jpg      1  \n",
       "18748  ./masked_data/product_img\\98.jpg      0  \n",
       "\n",
       "[18749 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['review_img_path','product_img_path', 'label'])\n",
    "df['review_img_path'] = review_img_path\n",
    "df['product_img_path'] = product_img_path\n",
    "df['label'] = label\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siames Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':256,\n",
    "    'EPOCHS':15,\n",
    "    'LEARNING_RATE':3e-3,\n",
    "    # 'LEARNING_RATE':10,\n",
    "    'BATCH_SIZE':8,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = 'a'\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=CFG['SEED'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset(Dataset):\n",
    "    def __init__(self,review_img_path,product_img_path,label,transform=None):\n",
    "        self.review_img_path = review_img_path\n",
    "        self.product_img_path = product_img_path\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        review_img = cv.imread(self.review_img_path[index])\n",
    "        product_img = cv.imread(self.product_img_path[index])\n",
    "        review_img = cv.resize(review_img, (CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "        product_img = cv.resize(product_img, (CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n",
    "        image = cv.hconcat([review_img, product_img])\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image  = self.transform(image=image)['image']\n",
    "    \n",
    "        return image, self.label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.review_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            ToTensorV2()\n",
    "                            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SiameseNetworkDataset(train[\"review_img_path\"].values, train[\"product_img_path\"].values, train[\"label\"].values, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "val_dataset = SiameseNetworkDataset(val[\"review_img_path\"].values, val[\"product_img_path\"].values, val[\"label\"].values, train_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adv_inception_v3', 'bat_resnext26ts', 'beit_base_patch16_224', 'beit_base_patch16_224_in22k', 'beit_base_patch16_384', 'beit_large_patch16_224', 'beit_large_patch16_224_in22k', 'beit_large_patch16_384', 'beit_large_patch16_512', 'beitv2_base_patch16_224', 'beitv2_base_patch16_224_in22k', 'beitv2_large_patch16_224', 'beitv2_large_patch16_224_in22k', 'botnet26t_256', 'cait_m36_384', 'cait_m48_448', 'cait_s24_224', 'cait_s24_384', 'cait_s36_384', 'cait_xs24_384', 'cait_xxs24_224', 'cait_xxs24_384', 'cait_xxs36_224', 'cait_xxs36_384', 'coat_lite_mini', 'coat_lite_small', 'coat_lite_tiny', 'coat_mini', 'coat_tiny', 'coatnet_0_rw_224', 'coatnet_1_rw_224', 'coatnet_bn_0_rw_224', 'coatnet_nano_rw_224', 'coatnet_rmlp_1_rw_224', 'coatnet_rmlp_2_rw_224', 'coatnet_rmlp_nano_rw_224', 'coatnext_nano_rw_224', 'convit_base', 'convit_small', 'convit_tiny', 'convmixer_768_32', 'convmixer_1024_20_ks9_p14', 'convmixer_1536_20', 'convnext_atto', 'convnext_atto_ols', 'convnext_base', 'convnext_base_384_in22ft1k', 'convnext_base_in22ft1k', 'convnext_base_in22k', 'convnext_femto', 'convnext_femto_ols', 'convnext_large', 'convnext_large_384_in22ft1k', 'convnext_large_in22ft1k', 'convnext_large_in22k', 'convnext_nano', 'convnext_nano_ols', 'convnext_pico', 'convnext_pico_ols', 'convnext_small', 'convnext_small_384_in22ft1k', 'convnext_small_in22ft1k', 'convnext_small_in22k', 'convnext_tiny', 'convnext_tiny_384_in22ft1k', 'convnext_tiny_hnf', 'convnext_tiny_in22ft1k', 'convnext_tiny_in22k', 'convnext_xlarge_384_in22ft1k', 'convnext_xlarge_in22ft1k', 'convnext_xlarge_in22k', 'crossvit_9_240', 'crossvit_9_dagger_240', 'crossvit_15_240', 'crossvit_15_dagger_240', 'crossvit_15_dagger_408', 'crossvit_18_240', 'crossvit_18_dagger_240', 'crossvit_18_dagger_408', 'crossvit_base_240', 'crossvit_small_240', 'crossvit_tiny_240', 'cs3darknet_focus_l', 'cs3darknet_focus_m', 'cs3darknet_l', 'cs3darknet_m', 'cs3darknet_x', 'cs3edgenet_x', 'cs3se_edgenet_x', 'cs3sedarknet_l', 'cs3sedarknet_x', 'cspdarknet53', 'cspresnet50', 'cspresnext50', 'darknet53', 'darknetaa53', 'deit3_base_patch16_224', 'deit3_base_patch16_224_in21ft1k', 'deit3_base_patch16_384', 'deit3_base_patch16_384_in21ft1k', 'deit3_huge_patch14_224', 'deit3_huge_patch14_224_in21ft1k', 'deit3_large_patch16_224', 'deit3_large_patch16_224_in21ft1k', 'deit3_large_patch16_384', 'deit3_large_patch16_384_in21ft1k', 'deit3_medium_patch16_224', 'deit3_medium_patch16_224_in21ft1k', 'deit3_small_patch16_224', 'deit3_small_patch16_224_in21ft1k', 'deit3_small_patch16_384', 'deit3_small_patch16_384_in21ft1k', 'deit_base_distilled_patch16_224', 'deit_base_distilled_patch16_384', 'deit_base_patch16_224', 'deit_base_patch16_384', 'deit_small_distilled_patch16_224', 'deit_small_patch16_224', 'deit_tiny_distilled_patch16_224', 'deit_tiny_patch16_224', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'densenetblur121d', 'dla34', 'dla46_c', 'dla46x_c', 'dla60', 'dla60_res2net', 'dla60_res2next', 'dla60x', 'dla60x_c', 'dla102', 'dla102x', 'dla102x2', 'dla169', 'dm_nfnet_f0', 'dm_nfnet_f1', 'dm_nfnet_f2', 'dm_nfnet_f3', 'dm_nfnet_f4', 'dm_nfnet_f5', 'dm_nfnet_f6', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn107', 'dpn131', 'eca_botnext26ts_256', 'eca_halonext26ts', 'eca_nfnet_l0', 'eca_nfnet_l1', 'eca_nfnet_l2', 'eca_resnet33ts', 'eca_resnext26ts', 'ecaresnet26t', 'ecaresnet50d', 'ecaresnet50d_pruned', 'ecaresnet50t', 'ecaresnet101d', 'ecaresnet101d_pruned', 'ecaresnet269d', 'ecaresnetlight', 'edgenext_base', 'edgenext_small', 'edgenext_small_rw', 'edgenext_x_small', 'edgenext_xx_small', 'efficientformer_l1', 'efficientformer_l3', 'efficientformer_l7', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b1_pruned', 'efficientnet_b2', 'efficientnet_b2_pruned', 'efficientnet_b3', 'efficientnet_b3_pruned', 'efficientnet_b4', 'efficientnet_el', 'efficientnet_el_pruned', 'efficientnet_em', 'efficientnet_es', 'efficientnet_es_pruned', 'efficientnet_lite0', 'efficientnetv2_rw_m', 'efficientnetv2_rw_s', 'efficientnetv2_rw_t', 'ens_adv_inception_resnet_v2', 'ese_vovnet19b_dw', 'ese_vovnet39b', 'fbnetc_100', 'fbnetv3_b', 'fbnetv3_d', 'fbnetv3_g', 'gc_efficientnetv2_rw_t', 'gcresnet33ts', 'gcresnet50t', 'gcresnext26ts', 'gcresnext50ts', 'gcvit_base', 'gcvit_small', 'gcvit_tiny', 'gcvit_xtiny', 'gcvit_xxtiny', 'gernet_l', 'gernet_m', 'gernet_s', 'ghostnet_100', 'gluon_inception_v3', 'gluon_resnet18_v1b', 'gluon_resnet34_v1b', 'gluon_resnet50_v1b', 'gluon_resnet50_v1c', 'gluon_resnet50_v1d', 'gluon_resnet50_v1s', 'gluon_resnet101_v1b', 'gluon_resnet101_v1c', 'gluon_resnet101_v1d', 'gluon_resnet101_v1s', 'gluon_resnet152_v1b', 'gluon_resnet152_v1c', 'gluon_resnet152_v1d', 'gluon_resnet152_v1s', 'gluon_resnext50_32x4d', 'gluon_resnext101_32x4d', 'gluon_resnext101_64x4d', 'gluon_senet154', 'gluon_seresnext50_32x4d', 'gluon_seresnext101_32x4d', 'gluon_seresnext101_64x4d', 'gluon_xception65', 'gmixer_24_224', 'gmlp_s16_224', 'halo2botnet50ts_256', 'halonet26t', 'halonet50ts', 'haloregnetz_b', 'hardcorenas_a', 'hardcorenas_b', 'hardcorenas_c', 'hardcorenas_d', 'hardcorenas_e', 'hardcorenas_f', 'hrnet_w18', 'hrnet_w18_small', 'hrnet_w18_small_v2', 'hrnet_w30', 'hrnet_w32', 'hrnet_w40', 'hrnet_w44', 'hrnet_w48', 'hrnet_w64', 'ig_resnext101_32x8d', 'ig_resnext101_32x16d', 'ig_resnext101_32x32d', 'ig_resnext101_32x48d', 'inception_resnet_v2', 'inception_v3', 'inception_v4', 'jx_nest_base', 'jx_nest_small', 'jx_nest_tiny', 'lambda_resnet26rpt_256', 'lambda_resnet26t', 'lambda_resnet50ts', 'lamhalobotnet50ts_256', 'lcnet_050', 'lcnet_075', 'lcnet_100', 'legacy_senet154', 'legacy_seresnet18', 'legacy_seresnet34', 'legacy_seresnet50', 'legacy_seresnet101', 'legacy_seresnet152', 'legacy_seresnext26_32x4d', 'legacy_seresnext50_32x4d', 'legacy_seresnext101_32x4d', 'levit_128', 'levit_128s', 'levit_192', 'levit_256', 'levit_384', 'maxvit_nano_rw_256', 'maxvit_rmlp_nano_rw_256', 'maxvit_rmlp_pico_rw_256', 'maxvit_rmlp_small_rw_224', 'maxvit_rmlp_tiny_rw_256', 'maxvit_tiny_rw_224', 'maxxvit_rmlp_nano_rw_256', 'maxxvit_rmlp_small_rw_256', 'mixer_b16_224', 'mixer_b16_224_in21k', 'mixer_b16_224_miil', 'mixer_b16_224_miil_in21k', 'mixer_l16_224', 'mixer_l16_224_in21k', 'mixnet_l', 'mixnet_m', 'mixnet_s', 'mixnet_xl', 'mnasnet_100', 'mnasnet_small', 'mobilenetv2_050', 'mobilenetv2_100', 'mobilenetv2_110d', 'mobilenetv2_120d', 'mobilenetv2_140', 'mobilenetv3_large_100', 'mobilenetv3_large_100_miil', 'mobilenetv3_large_100_miil_in21k', 'mobilenetv3_rw', 'mobilenetv3_small_050', 'mobilenetv3_small_075', 'mobilenetv3_small_100', 'mobilevit_s', 'mobilevit_xs', 'mobilevit_xxs', 'mobilevitv2_050', 'mobilevitv2_075', 'mobilevitv2_100', 'mobilevitv2_125', 'mobilevitv2_150', 'mobilevitv2_150_384_in22ft1k', 'mobilevitv2_150_in22ft1k', 'mobilevitv2_175', 'mobilevitv2_175_384_in22ft1k', 'mobilevitv2_175_in22ft1k', 'mobilevitv2_200', 'mobilevitv2_200_384_in22ft1k', 'mobilevitv2_200_in22ft1k', 'mvitv2_base', 'mvitv2_large', 'mvitv2_small', 'mvitv2_tiny', 'nasnetalarge', 'nf_regnet_b1', 'nf_resnet50', 'nfnet_l0', 'pit_b_224', 'pit_b_distilled_224', 'pit_s_224', 'pit_s_distilled_224', 'pit_ti_224', 'pit_ti_distilled_224', 'pit_xs_224', 'pit_xs_distilled_224', 'pnasnet5large', 'poolformer_m36', 'poolformer_m48', 'poolformer_s12', 'poolformer_s24', 'poolformer_s36', 'pvt_v2_b0', 'pvt_v2_b1', 'pvt_v2_b2', 'pvt_v2_b2_li', 'pvt_v2_b3', 'pvt_v2_b4', 'pvt_v2_b5', 'regnetv_040', 'regnetv_064', 'regnetx_002', 'regnetx_004', 'regnetx_006', 'regnetx_008', 'regnetx_016', 'regnetx_032', 'regnetx_040', 'regnetx_064', 'regnetx_080', 'regnetx_120', 'regnetx_160', 'regnetx_320', 'regnety_002', 'regnety_004', 'regnety_006', 'regnety_008', 'regnety_016', 'regnety_032', 'regnety_040', 'regnety_064', 'regnety_080', 'regnety_120', 'regnety_160', 'regnety_320', 'regnetz_040', 'regnetz_040h', 'regnetz_b16', 'regnetz_c16', 'regnetz_c16_evos', 'regnetz_d8', 'regnetz_d8_evos', 'regnetz_d32', 'regnetz_e8', 'repvgg_a2', 'repvgg_b0', 'repvgg_b1', 'repvgg_b1g4', 'repvgg_b2', 'repvgg_b2g4', 'repvgg_b3', 'repvgg_b3g4', 'res2net50_14w_8s', 'res2net50_26w_4s', 'res2net50_26w_6s', 'res2net50_26w_8s', 'res2net50_48w_2s', 'res2net101_26w_4s', 'res2next50', 'resmlp_12_224', 'resmlp_12_224_dino', 'resmlp_12_distilled_224', 'resmlp_24_224', 'resmlp_24_224_dino', 'resmlp_24_distilled_224', 'resmlp_36_224', 'resmlp_36_distilled_224', 'resmlp_big_24_224', 'resmlp_big_24_224_in22ft1k', 'resmlp_big_24_distilled_224', 'resnest14d', 'resnest26d', 'resnest50d', 'resnest50d_1s4x24d', 'resnest50d_4s2x40d', 'resnest101e', 'resnest200e', 'resnest269e', 'resnet10t', 'resnet14t', 'resnet18', 'resnet18d', 'resnet26', 'resnet26d', 'resnet26t', 'resnet32ts', 'resnet33ts', 'resnet34', 'resnet34d', 'resnet50', 'resnet50_gn', 'resnet50d', 'resnet51q', 'resnet61q', 'resnet101', 'resnet101d', 'resnet152', 'resnet152d', 'resnet200d', 'resnetaa50', 'resnetblur50', 'resnetrs50', 'resnetrs101', 'resnetrs152', 'resnetrs200', 'resnetrs270', 'resnetrs350', 'resnetrs420', 'resnetv2_50', 'resnetv2_50d_evos', 'resnetv2_50d_gn', 'resnetv2_50x1_bit_distilled', 'resnetv2_50x1_bitm', 'resnetv2_50x1_bitm_in21k', 'resnetv2_50x3_bitm', 'resnetv2_50x3_bitm_in21k', 'resnetv2_101', 'resnetv2_101x1_bitm', 'resnetv2_101x1_bitm_in21k', 'resnetv2_101x3_bitm', 'resnetv2_101x3_bitm_in21k', 'resnetv2_152x2_bit_teacher', 'resnetv2_152x2_bit_teacher_384', 'resnetv2_152x2_bitm', 'resnetv2_152x2_bitm_in21k', 'resnetv2_152x4_bitm', 'resnetv2_152x4_bitm_in21k', 'resnext26ts', 'resnext50_32x4d', 'resnext50d_32x4d', 'resnext101_32x8d', 'resnext101_64x4d', 'rexnet_100', 'rexnet_130', 'rexnet_150', 'rexnet_200', 'sebotnet33ts_256', 'sehalonet33ts', 'selecsls42b', 'selecsls60', 'selecsls60b', 'semnasnet_075', 'semnasnet_100', 'sequencer2d_l', 'sequencer2d_m', 'sequencer2d_s', 'seresnet33ts', 'seresnet50', 'seresnet152d', 'seresnext26d_32x4d', 'seresnext26t_32x4d', 'seresnext26ts', 'seresnext50_32x4d', 'seresnext101_32x8d', 'seresnext101d_32x8d', 'seresnextaa101d_32x8d', 'skresnet18', 'skresnet34', 'skresnext50_32x4d', 'spnasnet_100', 'ssl_resnet18', 'ssl_resnet50', 'ssl_resnext50_32x4d', 'ssl_resnext101_32x4d', 'ssl_resnext101_32x8d', 'ssl_resnext101_32x16d', 'swin_base_patch4_window7_224', 'swin_base_patch4_window7_224_in22k', 'swin_base_patch4_window12_384', 'swin_base_patch4_window12_384_in22k', 'swin_large_patch4_window7_224', 'swin_large_patch4_window7_224_in22k', 'swin_large_patch4_window12_384', 'swin_large_patch4_window12_384_in22k', 'swin_s3_base_224', 'swin_s3_small_224', 'swin_s3_tiny_224', 'swin_small_patch4_window7_224', 'swin_tiny_patch4_window7_224', 'swinv2_base_window8_256', 'swinv2_base_window12_192_22k', 'swinv2_base_window12to16_192to256_22kft1k', 'swinv2_base_window12to24_192to384_22kft1k', 'swinv2_base_window16_256', 'swinv2_cr_small_224', 'swinv2_cr_small_ns_224', 'swinv2_cr_tiny_ns_224', 'swinv2_large_window12_192_22k', 'swinv2_large_window12to16_192to256_22kft1k', 'swinv2_large_window12to24_192to384_22kft1k', 'swinv2_small_window8_256', 'swinv2_small_window16_256', 'swinv2_tiny_window8_256', 'swinv2_tiny_window16_256', 'swsl_resnet18', 'swsl_resnet50', 'swsl_resnext50_32x4d', 'swsl_resnext101_32x4d', 'swsl_resnext101_32x8d', 'swsl_resnext101_32x16d', 'tf_efficientnet_b0', 'tf_efficientnet_b0_ap', 'tf_efficientnet_b0_ns', 'tf_efficientnet_b1', 'tf_efficientnet_b1_ap', 'tf_efficientnet_b1_ns', 'tf_efficientnet_b2', 'tf_efficientnet_b2_ap', 'tf_efficientnet_b2_ns', 'tf_efficientnet_b3', 'tf_efficientnet_b3_ap', 'tf_efficientnet_b3_ns', 'tf_efficientnet_b4', 'tf_efficientnet_b4_ap', 'tf_efficientnet_b4_ns', 'tf_efficientnet_b5', 'tf_efficientnet_b5_ap', 'tf_efficientnet_b5_ns', 'tf_efficientnet_b6', 'tf_efficientnet_b6_ap', 'tf_efficientnet_b6_ns', 'tf_efficientnet_b7', 'tf_efficientnet_b7_ap', 'tf_efficientnet_b7_ns', 'tf_efficientnet_b8', 'tf_efficientnet_b8_ap', 'tf_efficientnet_cc_b0_4e', 'tf_efficientnet_cc_b0_8e', 'tf_efficientnet_cc_b1_8e', 'tf_efficientnet_el', 'tf_efficientnet_em', 'tf_efficientnet_es', 'tf_efficientnet_l2_ns', 'tf_efficientnet_l2_ns_475', 'tf_efficientnet_lite0', 'tf_efficientnet_lite1', 'tf_efficientnet_lite2', 'tf_efficientnet_lite3', 'tf_efficientnet_lite4', 'tf_efficientnetv2_b0', 'tf_efficientnetv2_b1', 'tf_efficientnetv2_b2', 'tf_efficientnetv2_b3', 'tf_efficientnetv2_l', 'tf_efficientnetv2_l_in21ft1k', 'tf_efficientnetv2_l_in21k', 'tf_efficientnetv2_m', 'tf_efficientnetv2_m_in21ft1k', 'tf_efficientnetv2_m_in21k', 'tf_efficientnetv2_s', 'tf_efficientnetv2_s_in21ft1k', 'tf_efficientnetv2_s_in21k', 'tf_efficientnetv2_xl_in21ft1k', 'tf_efficientnetv2_xl_in21k', 'tf_inception_v3', 'tf_mixnet_l', 'tf_mixnet_m', 'tf_mixnet_s', 'tf_mobilenetv3_large_075', 'tf_mobilenetv3_large_100', 'tf_mobilenetv3_large_minimal_100', 'tf_mobilenetv3_small_075', 'tf_mobilenetv3_small_100', 'tf_mobilenetv3_small_minimal_100', 'tinynet_a', 'tinynet_b', 'tinynet_c', 'tinynet_d', 'tinynet_e', 'tnt_s_patch16_224', 'tresnet_l', 'tresnet_l_448', 'tresnet_m', 'tresnet_m_448', 'tresnet_m_miil_in21k', 'tresnet_v2_l', 'tresnet_xl', 'tresnet_xl_448', 'tv_densenet121', 'tv_resnet34', 'tv_resnet50', 'tv_resnet101', 'tv_resnet152', 'tv_resnext50_32x4d', 'twins_pcpvt_base', 'twins_pcpvt_large', 'twins_pcpvt_small', 'twins_svt_base', 'twins_svt_large', 'twins_svt_small', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'visformer_small', 'vit_base_patch8_224', 'vit_base_patch8_224_dino', 'vit_base_patch8_224_in21k', 'vit_base_patch16_224', 'vit_base_patch16_224_dino', 'vit_base_patch16_224_in21k', 'vit_base_patch16_224_miil', 'vit_base_patch16_224_miil_in21k', 'vit_base_patch16_224_sam', 'vit_base_patch16_384', 'vit_base_patch16_rpn_224', 'vit_base_patch32_224', 'vit_base_patch32_224_clip_laion2b', 'vit_base_patch32_224_in21k', 'vit_base_patch32_224_sam', 'vit_base_patch32_384', 'vit_base_r50_s16_224_in21k', 'vit_base_r50_s16_384', 'vit_giant_patch14_224_clip_laion2b', 'vit_huge_patch14_224_clip_laion2b', 'vit_huge_patch14_224_in21k', 'vit_large_patch14_224_clip_laion2b', 'vit_large_patch16_224', 'vit_large_patch16_224_in21k', 'vit_large_patch16_384', 'vit_large_patch32_224_in21k', 'vit_large_patch32_384', 'vit_large_r50_s32_224', 'vit_large_r50_s32_224_in21k', 'vit_large_r50_s32_384', 'vit_relpos_base_patch16_224', 'vit_relpos_base_patch16_clsgap_224', 'vit_relpos_base_patch32_plus_rpn_256', 'vit_relpos_medium_patch16_224', 'vit_relpos_medium_patch16_cls_224', 'vit_relpos_medium_patch16_rpn_224', 'vit_relpos_small_patch16_224', 'vit_small_patch8_224_dino', 'vit_small_patch16_224', 'vit_small_patch16_224_dino', 'vit_small_patch16_224_in21k', 'vit_small_patch16_384', 'vit_small_patch32_224', 'vit_small_patch32_224_in21k', 'vit_small_patch32_384', 'vit_small_r26_s32_224', 'vit_small_r26_s32_224_in21k', 'vit_small_r26_s32_384', 'vit_srelpos_medium_patch16_224', 'vit_srelpos_small_patch16_224', 'vit_tiny_patch16_224', 'vit_tiny_patch16_224_in21k', 'vit_tiny_patch16_384', 'vit_tiny_r_s16_p8_224', 'vit_tiny_r_s16_p8_224_in21k', 'vit_tiny_r_s16_p8_384', 'volo_d1_224', 'volo_d1_384', 'volo_d2_224', 'volo_d2_384', 'volo_d3_224', 'volo_d3_448', 'volo_d4_224', 'volo_d4_448', 'volo_d5_224', 'volo_d5_448', 'volo_d5_512', 'wide_resnet50_2', 'wide_resnet101_2', 'xception', 'xception41', 'xception41p', 'xception65', 'xception65p', 'xception71', 'xcit_large_24_p8_224', 'xcit_large_24_p8_224_dist', 'xcit_large_24_p8_384_dist', 'xcit_large_24_p16_224', 'xcit_large_24_p16_224_dist', 'xcit_large_24_p16_384_dist', 'xcit_medium_24_p8_224', 'xcit_medium_24_p8_224_dist', 'xcit_medium_24_p8_384_dist', 'xcit_medium_24_p16_224', 'xcit_medium_24_p16_224_dist', 'xcit_medium_24_p16_384_dist', 'xcit_nano_12_p8_224', 'xcit_nano_12_p8_224_dist', 'xcit_nano_12_p8_384_dist', 'xcit_nano_12_p16_224', 'xcit_nano_12_p16_224_dist', 'xcit_nano_12_p16_384_dist', 'xcit_small_12_p8_224', 'xcit_small_12_p8_224_dist', 'xcit_small_12_p8_384_dist', 'xcit_small_12_p16_224', 'xcit_small_12_p16_224_dist', 'xcit_small_12_p16_384_dist', 'xcit_small_24_p8_224', 'xcit_small_24_p8_224_dist', 'xcit_small_24_p8_384_dist', 'xcit_small_24_p16_224', 'xcit_small_24_p16_224_dist', 'xcit_small_24_p16_384_dist', 'xcit_tiny_12_p8_224', 'xcit_tiny_12_p8_224_dist', 'xcit_tiny_12_p8_384_dist', 'xcit_tiny_12_p16_224', 'xcit_tiny_12_p16_224_dist', 'xcit_tiny_12_p16_384_dist', 'xcit_tiny_24_p8_224', 'xcit_tiny_24_p8_224_dist', 'xcit_tiny_24_p8_384_dist', 'xcit_tiny_24_p16_224', 'xcit_tiny_24_p16_224_dist', 'xcit_tiny_24_p16_384_dist']\n"
     ]
    }
   ],
   "source": [
    "avail_pretrained_models = timm.list_models(pretrained=True)\n",
    "print(avail_pretrained_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "        # self.backbone = timm.create_model('maxvit_tiny_tf_512', pretrained=True)\n",
    "        self.backbone = timm.create_model('efficientnet_b0', pretrained=False)\n",
    "        self.classifier1 = nn.Linear(1000, 10)\n",
    "        self.classifier2 = nn.Linear(10, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier1(x)\n",
    "        x = self.classifier2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.LongTensor).to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            # print(pred.shape)\n",
    "            \n",
    "            loss = criterion(pred, labels)\n",
    "            \n",
    "            preds += pred.detach().argmax(1).cpu().numpy().tolist()\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "            \n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_score = accuracy_score(true_labels, preds, normalize= True)\n",
    "        \n",
    "    \n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model = model.to(device)\n",
    "    # criterion = nn.BCEWithLogitsLoss.to(device)\n",
    "    # criterion = nn.BCEWithLogitsLoss(weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None).to(device)\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = nn.NLLLoss(reduction=\"sum\").to(device)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(0, CFG['EPOCHS']):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for imgs, labels in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.LongTensor).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "            # with autocast():\n",
    "            #     output = model(imgs)\n",
    "            #     print(output)\n",
    "            #     loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scaler.scale(loss).backward()\n",
    "            # scaler.step(optimizer)\n",
    "            # scaler.update()\n",
    "            # print(loss.item())\n",
    "            train_loss.append(loss.item())\n",
    "                    \n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val accuracy score : [{_val_score:.5f}]')\n",
    "       \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "            \n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                  Parent Layers             Layer (type)           Input Shape         Param #     Tr. Param #\n",
      "==============================================================================================================================================\n",
      "                                         BaseModel/EfficientNet                 Conv2d-1      [8, 3, 256, 256]             864             864\n",
      "                          BaseModel/EfficientNet/BatchNormAct2d               Identity-2     [8, 32, 128, 128]               0               0\n",
      "                          BaseModel/EfficientNet/BatchNormAct2d                   SiLU-3     [8, 32, 128, 128]               0               0\n",
      "                  BaseModel/EfficientNet/DepthwiseSeparableConv                 Conv2d-4     [8, 32, 128, 128]             288             288\n",
      "   BaseModel/EfficientNet/DepthwiseSeparableConv/BatchNormAct2d               Identity-5     [8, 32, 128, 128]               0               0\n",
      "   BaseModel/EfficientNet/DepthwiseSeparableConv/BatchNormAct2d                   SiLU-6     [8, 32, 128, 128]               0               0\n",
      "    BaseModel/EfficientNet/DepthwiseSeparableConv/SqueezeExcite                 Conv2d-7         [8, 32, 1, 1]             264             264\n",
      "    BaseModel/EfficientNet/DepthwiseSeparableConv/SqueezeExcite                   SiLU-8          [8, 8, 1, 1]               0               0\n",
      "    BaseModel/EfficientNet/DepthwiseSeparableConv/SqueezeExcite                 Conv2d-9          [8, 8, 1, 1]             288             288\n",
      "    BaseModel/EfficientNet/DepthwiseSeparableConv/SqueezeExcite               Sigmoid-10         [8, 32, 1, 1]               0               0\n",
      "                  BaseModel/EfficientNet/DepthwiseSeparableConv                Conv2d-11     [8, 32, 128, 128]             512             512\n",
      "   BaseModel/EfficientNet/DepthwiseSeparableConv/BatchNormAct2d              Identity-12     [8, 16, 128, 128]               0               0\n",
      "   BaseModel/EfficientNet/DepthwiseSeparableConv/BatchNormAct2d              Identity-13     [8, 16, 128, 128]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-14     [8, 16, 128, 128]           1,536           1,536\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-15     [8, 96, 128, 128]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                  SiLU-16     [8, 96, 128, 128]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-17     [8, 96, 128, 128]             864             864\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-18       [8, 96, 64, 64]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                  SiLU-19       [8, 96, 64, 64]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                Conv2d-20         [8, 96, 1, 1]             388             388\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                  SiLU-21          [8, 4, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                Conv2d-22          [8, 4, 1, 1]             480             480\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Sigmoid-23         [8, 96, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-24       [8, 96, 64, 64]           2,304           2,304\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-25       [8, 24, 64, 64]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-26       [8, 24, 64, 64]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-27       [8, 24, 64, 64]           3,456           3,456\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-28      [8, 144, 64, 64]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                  SiLU-29      [8, 144, 64, 64]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-30      [8, 144, 64, 64]           1,296           1,296\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-31      [8, 144, 64, 64]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                  SiLU-32      [8, 144, 64, 64]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                Conv2d-33        [8, 144, 1, 1]             870             870\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                  SiLU-34          [8, 6, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                Conv2d-35          [8, 6, 1, 1]           1,008           1,008\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Sigmoid-36        [8, 144, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-37      [8, 144, 64, 64]           3,456           3,456\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-38       [8, 24, 64, 64]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-39       [8, 24, 64, 64]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual              Identity-40       [8, 24, 64, 64]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-41       [8, 24, 64, 64]           3,456           3,456\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-42      [8, 144, 64, 64]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                  SiLU-43      [8, 144, 64, 64]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-44      [8, 144, 64, 64]           3,600           3,600\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-45      [8, 144, 32, 32]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                  SiLU-46      [8, 144, 32, 32]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                Conv2d-47        [8, 144, 1, 1]             870             870\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                  SiLU-48          [8, 6, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                Conv2d-49          [8, 6, 1, 1]           1,008           1,008\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Sigmoid-50        [8, 144, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-51      [8, 144, 32, 32]           5,760           5,760\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-52       [8, 40, 32, 32]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-53       [8, 40, 32, 32]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-54       [8, 40, 32, 32]           9,600           9,600\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-55      [8, 240, 32, 32]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                  SiLU-56      [8, 240, 32, 32]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-57      [8, 240, 32, 32]           6,000           6,000\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-58      [8, 240, 32, 32]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                  SiLU-59      [8, 240, 32, 32]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                Conv2d-60        [8, 240, 1, 1]           2,410           2,410\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                  SiLU-61         [8, 10, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                Conv2d-62         [8, 10, 1, 1]           2,640           2,640\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Sigmoid-63        [8, 240, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-64      [8, 240, 32, 32]           9,600           9,600\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-65       [8, 40, 32, 32]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-66       [8, 40, 32, 32]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual              Identity-67       [8, 40, 32, 32]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-68       [8, 40, 32, 32]           9,600           9,600\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-69      [8, 240, 32, 32]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                  SiLU-70      [8, 240, 32, 32]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-71      [8, 240, 32, 32]           2,160           2,160\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-72      [8, 240, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                  SiLU-73      [8, 240, 16, 16]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                Conv2d-74        [8, 240, 1, 1]           2,410           2,410\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                  SiLU-75         [8, 10, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                Conv2d-76         [8, 10, 1, 1]           2,640           2,640\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Sigmoid-77        [8, 240, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-78      [8, 240, 16, 16]          19,200          19,200\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-79       [8, 80, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-80       [8, 80, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-81       [8, 80, 16, 16]          38,400          38,400\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-82      [8, 480, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                  SiLU-83      [8, 480, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-84      [8, 480, 16, 16]           4,320           4,320\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-85      [8, 480, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                  SiLU-86      [8, 480, 16, 16]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                Conv2d-87        [8, 480, 1, 1]           9,620           9,620\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                  SiLU-88         [8, 20, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                Conv2d-89         [8, 20, 1, 1]          10,080          10,080\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Sigmoid-90        [8, 480, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-91      [8, 480, 16, 16]          38,400          38,400\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-92       [8, 80, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-93       [8, 80, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual              Identity-94       [8, 80, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-95       [8, 80, 16, 16]          38,400          38,400\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-96      [8, 480, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                  SiLU-97      [8, 480, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual                Conv2d-98      [8, 480, 16, 16]           4,320           4,320\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d              Identity-99      [8, 480, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-100      [8, 480, 16, 16]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-101        [8, 480, 1, 1]           9,620           9,620\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                 SiLU-102         [8, 20, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-103         [8, 20, 1, 1]          10,080          10,080\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite              Sigmoid-104        [8, 480, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-105      [8, 480, 16, 16]          38,400          38,400\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-106       [8, 80, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-107       [8, 80, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual             Identity-108       [8, 80, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-109       [8, 80, 16, 16]          38,400          38,400\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-110      [8, 480, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-111      [8, 480, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-112      [8, 480, 16, 16]          12,000          12,000\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-113      [8, 480, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-114      [8, 480, 16, 16]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-115        [8, 480, 1, 1]           9,620           9,620\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                 SiLU-116         [8, 20, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-117         [8, 20, 1, 1]          10,080          10,080\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite              Sigmoid-118        [8, 480, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-119      [8, 480, 16, 16]          53,760          53,760\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-120      [8, 112, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-121      [8, 112, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-122      [8, 112, 16, 16]          75,264          75,264\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-123      [8, 672, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-124      [8, 672, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-125      [8, 672, 16, 16]          16,800          16,800\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-126      [8, 672, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-127      [8, 672, 16, 16]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-128        [8, 672, 1, 1]          18,844          18,844\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                 SiLU-129         [8, 28, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-130         [8, 28, 1, 1]          19,488          19,488\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite              Sigmoid-131        [8, 672, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-132      [8, 672, 16, 16]          75,264          75,264\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-133      [8, 112, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-134      [8, 112, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual             Identity-135      [8, 112, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-136      [8, 112, 16, 16]          75,264          75,264\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-137      [8, 672, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-138      [8, 672, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-139      [8, 672, 16, 16]          16,800          16,800\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-140      [8, 672, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-141      [8, 672, 16, 16]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-142        [8, 672, 1, 1]          18,844          18,844\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                 SiLU-143         [8, 28, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-144         [8, 28, 1, 1]          19,488          19,488\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite              Sigmoid-145        [8, 672, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-146      [8, 672, 16, 16]          75,264          75,264\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-147      [8, 112, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-148      [8, 112, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual             Identity-149      [8, 112, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-150      [8, 112, 16, 16]          75,264          75,264\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-151      [8, 672, 16, 16]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-152      [8, 672, 16, 16]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-153      [8, 672, 16, 16]          16,800          16,800\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-154        [8, 672, 8, 8]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-155        [8, 672, 8, 8]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-156        [8, 672, 1, 1]          18,844          18,844\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                 SiLU-157         [8, 28, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-158         [8, 28, 1, 1]          19,488          19,488\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite              Sigmoid-159        [8, 672, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-160        [8, 672, 8, 8]         129,024         129,024\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-161        [8, 192, 8, 8]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-162        [8, 192, 8, 8]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-163        [8, 192, 8, 8]         221,184         221,184\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-164       [8, 1152, 8, 8]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-165       [8, 1152, 8, 8]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-166       [8, 1152, 8, 8]          28,800          28,800\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-167       [8, 1152, 8, 8]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-168       [8, 1152, 8, 8]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-169       [8, 1152, 1, 1]          55,344          55,344\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                 SiLU-170         [8, 48, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-171         [8, 48, 1, 1]          56,448          56,448\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite              Sigmoid-172       [8, 1152, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-173       [8, 1152, 8, 8]         221,184         221,184\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-174        [8, 192, 8, 8]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-175        [8, 192, 8, 8]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual             Identity-176        [8, 192, 8, 8]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-177        [8, 192, 8, 8]         221,184         221,184\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-178       [8, 1152, 8, 8]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-179       [8, 1152, 8, 8]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-180       [8, 1152, 8, 8]          28,800          28,800\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-181       [8, 1152, 8, 8]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-182       [8, 1152, 8, 8]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-183       [8, 1152, 1, 1]          55,344          55,344\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                 SiLU-184         [8, 48, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-185         [8, 48, 1, 1]          56,448          56,448\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite              Sigmoid-186       [8, 1152, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-187       [8, 1152, 8, 8]         221,184         221,184\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-188        [8, 192, 8, 8]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-189        [8, 192, 8, 8]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual             Identity-190        [8, 192, 8, 8]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-191        [8, 192, 8, 8]         221,184         221,184\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-192       [8, 1152, 8, 8]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-193       [8, 1152, 8, 8]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-194       [8, 1152, 8, 8]          28,800          28,800\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-195       [8, 1152, 8, 8]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-196       [8, 1152, 8, 8]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-197       [8, 1152, 1, 1]          55,344          55,344\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                 SiLU-198         [8, 48, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-199         [8, 48, 1, 1]          56,448          56,448\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite              Sigmoid-200       [8, 1152, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-201       [8, 1152, 8, 8]         221,184         221,184\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-202        [8, 192, 8, 8]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-203        [8, 192, 8, 8]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual             Identity-204        [8, 192, 8, 8]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-205        [8, 192, 8, 8]         221,184         221,184\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-206       [8, 1152, 8, 8]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-207       [8, 1152, 8, 8]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-208       [8, 1152, 8, 8]          10,368          10,368\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-209       [8, 1152, 8, 8]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d                 SiLU-210       [8, 1152, 8, 8]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-211       [8, 1152, 1, 1]          55,344          55,344\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite                 SiLU-212         [8, 48, 1, 1]               0               0\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite               Conv2d-213         [8, 48, 1, 1]          56,448          56,448\n",
      "          BaseModel/EfficientNet/InvertedResidual/SqueezeExcite              Sigmoid-214       [8, 1152, 1, 1]               0               0\n",
      "                        BaseModel/EfficientNet/InvertedResidual               Conv2d-215       [8, 1152, 8, 8]         368,640         368,640\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-216        [8, 320, 8, 8]               0               0\n",
      "         BaseModel/EfficientNet/InvertedResidual/BatchNormAct2d             Identity-217        [8, 320, 8, 8]               0               0\n",
      "                                         BaseModel/EfficientNet               Conv2d-218        [8, 320, 8, 8]         409,600         409,600\n",
      "                          BaseModel/EfficientNet/BatchNormAct2d             Identity-219       [8, 1280, 8, 8]               0               0\n",
      "                          BaseModel/EfficientNet/BatchNormAct2d                 SiLU-220       [8, 1280, 8, 8]               0               0\n",
      "                    BaseModel/EfficientNet/SelectAdaptivePool2d    AdaptiveAvgPool2d-221       [8, 1280, 8, 8]               0               0\n",
      "                    BaseModel/EfficientNet/SelectAdaptivePool2d              Flatten-222       [8, 1280, 1, 1]               0               0\n",
      "                                         BaseModel/EfficientNet               Linear-223             [8, 1280]       1,281,000       1,281,000\n",
      "                                                      BaseModel               Linear-224             [8, 1000]          10,010          10,010\n",
      "                                                      BaseModel               Linear-225               [8, 10]              22              22\n",
      "==============================================================================================================================================\n",
      "Total params: 5,256,564\n",
      "Trainable params: 5,256,564\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "model.load_state_dict(torch.load('./eff0b_10.pt'))\n",
    "model.eval()\n",
    "print(pytorch_model_summary.summary(model, torch.zeros(8,3,256,256),max_depth=None, show_parent_layers=True, show_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [03:02<00:00,  8.98it/s]\n",
      "100%|██████████| 704/704 [00:38<00:00, 18.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [4.64291] Val Loss : [4.50620] Val accuracy score : [0.70187]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [02:56<00:00,  9.30it/s]\n",
      "100%|██████████| 704/704 [00:39<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [4.58621] Val Loss : [4.44923] Val accuracy score : [0.70240]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [02:55<00:00,  9.34it/s]\n",
      "100%|██████████| 704/704 [00:37<00:00, 18.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [4.52128] Val Loss : [4.45422] Val accuracy score : [0.70436]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [02:57<00:00,  9.24it/s]\n",
      "100%|██████████| 704/704 [00:40<00:00, 17.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [4.44191] Val Loss : [4.43864] Val accuracy score : [0.70027]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [03:02<00:00,  8.97it/s]\n",
      "100%|██████████| 704/704 [00:38<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [4.39240] Val Loss : [4.44876] Val accuracy score : [0.70898]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [03:03<00:00,  8.95it/s]\n",
      "100%|██████████| 704/704 [00:39<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [4.32017] Val Loss : [4.41776] Val accuracy score : [0.71236]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [03:08<00:00,  8.69it/s]\n",
      "100%|██████████| 704/704 [00:45<00:00, 15.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [4.27319] Val Loss : [4.41768] Val accuracy score : [0.71360]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [03:03<00:00,  8.95it/s]\n",
      "100%|██████████| 704/704 [00:43<00:00, 16.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [4.19346] Val Loss : [4.40277] Val accuracy score : [0.72018]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [02:59<00:00,  9.12it/s]\n",
      "100%|██████████| 704/704 [00:41<00:00, 17.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [4.17673] Val Loss : [4.42657] Val accuracy score : [0.71858]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [03:01<00:00,  9.06it/s]\n",
      "100%|██████████| 704/704 [00:45<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [4.07588] Val Loss : [4.41273] Val accuracy score : [0.71893]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [03:02<00:00,  8.98it/s]\n",
      "100%|██████████| 704/704 [00:41<00:00, 16.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [3.99891] Val Loss : [4.49530] Val accuracy score : [0.70827]\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.5000e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [03:04<00:00,  8.90it/s]\n",
      "100%|██████████| 704/704 [00:45<00:00, 15.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [3.73023] Val Loss : [4.54353] Val accuracy score : [0.71253]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [02:51<00:00,  9.57it/s]\n",
      "100%|██████████| 704/704 [00:50<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [3.51162] Val Loss : [4.77844] Val accuracy score : [0.70133]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [02:44<00:00, 10.00it/s]\n",
      "100%|██████████| 704/704 [00:50<00:00, 14.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [3.33263] Val Loss : [4.98154] Val accuracy score : [0.69458]\n",
      "Epoch 00014: reducing learning rate of group 0 to 7.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [02:44<00:00,  9.99it/s]\n",
      "100%|██████████| 704/704 [00:50<00:00, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [3.08029] Val Loss : [5.30304] Val accuracy score : [0.69707]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=3e-5, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./eff0b_25.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
