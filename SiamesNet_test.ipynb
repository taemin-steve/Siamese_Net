{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import glob\n",
    "import cv2 as cv\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from tqdm.auto import tqdm\n",
    "import timm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make DataFrame\n",
    "\n",
    "## columns: review_img_path, product_img_path, label \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_product_img_list = glob.glob('./masked_data/product_img/*')\n",
    "all_product_img_list = sorted(all_product_img_list)\n",
    "# print(all_product_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_img_path = []\n",
    "product_img_path = []\n",
    "label = []\n",
    "for product_img in all_product_img_list:\n",
    "    glob_img_list = []\n",
    "    str = product_img.split(\"/\")[3]\n",
    "    str = str.split(\".\")[0]\n",
    "    glob_img_list = glob.glob('./masked_data/review_img/'+str +'_review_img/O/*.jpg')\n",
    "    review_img_path = review_img_path + glob_img_list\n",
    "    product_img_path = product_img_path + [product_img  for i in range(len(glob_img_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5389\n",
      "5389\n"
     ]
    }
   ],
   "source": [
    "print(len(product_img_path))\n",
    "print(len(review_img_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(review_img_path)):\n",
    "    random_number = random.randint(0, 1)\n",
    "    if random_number == 0:\n",
    "        label.append(0)\n",
    "    else:\n",
    "        review_num = review_img_path[i].split('/')[3]\n",
    "        review_num = review_num.split(\"_\")[0]\n",
    "        random_number = random.randint(0, len(all_product_img_list) - 1)\n",
    "        while review_num == random_number:\n",
    "            random_number = random.randint(0, len(all_product_img_list) - 1)\n",
    "        product_img_path[i] = all_product_img_list[random_number]\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_img_path</th>\n",
       "      <th>product_img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./masked_data/review_img/0_review_img/O/404.jpg</td>\n",
       "      <td>./masked_data/product_img/0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./masked_data/review_img/0_review_img/O/174.jpg</td>\n",
       "      <td>./masked_data/product_img/0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./masked_data/review_img/0_review_img/O/93.jpg</td>\n",
       "      <td>./masked_data/product_img/0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./masked_data/review_img/0_review_img/O/177.jpg</td>\n",
       "      <td>./masked_data/product_img/62.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./masked_data/review_img/0_review_img/O/399.jpg</td>\n",
       "      <td>./masked_data/product_img/0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5384</th>\n",
       "      <td>./masked_data/review_img/98_review_img/O/194.jpg</td>\n",
       "      <td>./masked_data/product_img/14.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>./masked_data/review_img/98_review_img/O/148.jpg</td>\n",
       "      <td>./masked_data/product_img/10.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5386</th>\n",
       "      <td>./masked_data/review_img/98_review_img/O/401.jpg</td>\n",
       "      <td>./masked_data/product_img/77.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>./masked_data/review_img/98_review_img/O/433.jpg</td>\n",
       "      <td>./masked_data/product_img/98.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>./masked_data/review_img/98_review_img/O/295.jpg</td>\n",
       "      <td>./masked_data/product_img/98.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5389 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       review_img_path   \n",
       "0      ./masked_data/review_img/0_review_img/O/404.jpg  \\\n",
       "1      ./masked_data/review_img/0_review_img/O/174.jpg   \n",
       "2       ./masked_data/review_img/0_review_img/O/93.jpg   \n",
       "3      ./masked_data/review_img/0_review_img/O/177.jpg   \n",
       "4      ./masked_data/review_img/0_review_img/O/399.jpg   \n",
       "...                                                ...   \n",
       "5384  ./masked_data/review_img/98_review_img/O/194.jpg   \n",
       "5385  ./masked_data/review_img/98_review_img/O/148.jpg   \n",
       "5386  ./masked_data/review_img/98_review_img/O/401.jpg   \n",
       "5387  ./masked_data/review_img/98_review_img/O/433.jpg   \n",
       "5388  ./masked_data/review_img/98_review_img/O/295.jpg   \n",
       "\n",
       "                      product_img_path  label  \n",
       "0      ./masked_data/product_img/0.jpg      0  \n",
       "1      ./masked_data/product_img/0.jpg      0  \n",
       "2      ./masked_data/product_img/0.jpg      0  \n",
       "3     ./masked_data/product_img/62.jpg      1  \n",
       "4      ./masked_data/product_img/0.jpg      0  \n",
       "...                                ...    ...  \n",
       "5384  ./masked_data/product_img/14.jpg      1  \n",
       "5385  ./masked_data/product_img/10.jpg      1  \n",
       "5386  ./masked_data/product_img/77.jpg      1  \n",
       "5387  ./masked_data/product_img/98.jpg      0  \n",
       "5388  ./masked_data/product_img/98.jpg      0  \n",
       "\n",
       "[5389 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['review_img_path','product_img_path', 'label'])\n",
    "df['review_img_path'] = review_img_path\n",
    "df['product_img_path'] = product_img_path\n",
    "df['label'] = label\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siames Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':256,\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    'BATCH_SIZE':4,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=CFG['SEED'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset(Dataset):\n",
    "    def __init__(self,review_img_path,product_img_path,label,transform=None):\n",
    "        self.review_img_path = review_img_path\n",
    "        self.product_img_path = product_img_path\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        review_img = cv.imread(self.review_img_path[index],cv.COLOR_BGR2GRAY)\n",
    "        product_img = cv.imread(self.product_img_path[index], cv.COLOR_BGR2GRAY)\n",
    "        # review_img = Image.open(self.review_img_path[index])\n",
    "        # product_img = Image.open(self.product_img_path[index])\n",
    "        # review_img = review_img.convert(\"L\")\n",
    "        # product_img = product_img.convert(\"L\")\n",
    "        \n",
    "\n",
    "        if self.transform is not None:\n",
    "            review_img = self.transform(image= review_img)['image']\n",
    "            product_img = self.transform(image= product_img)['image']\n",
    "        # print(np.array([int(label[index])], dtype=np.float32))\n",
    "        return review_img, product_img, torch.from_numpy(np.array([int(label[index])], dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.review_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            # A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SiameseNetworkDataset(train[\"review_img_path\"].values, train[\"product_img_path\"].values, train[\"label\"].values, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':256,\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    'BATCH_SIZE':4,\n",
    "    'SEED':40\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = 'a'\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed ê³ ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "        self.classifier = nn.Linear(1000, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Contrastive Loss Function\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "      # Calculate the euclidian distance and calculate the contrastive loss\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, device):\n",
    "    model.to(device)\n",
    "    criterion = ContrastiveLoss().to(device)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for review_img, product_img, labels in tqdm(iter(train_loader)):\n",
    "            review_img = review_img.float().to(device)\n",
    "            product_img = product_img.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                output1 = model(review_img)\n",
    "                output2 = model(product_img)\n",
    "                loss = criterion(output1,output2,labels)\n",
    "\n",
    "            \n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "                    \n",
    "        # _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}]')\n",
    "       \n",
    "        # if scheduler is not None:\n",
    "        #     scheduler.step(_val_score)\n",
    "            \n",
    "        # if best_score < _val_score:\n",
    "        #     best_score = _val_score\n",
    "        #     best_model = model\n",
    "        best_model = model\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 943/943 [03:11<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [1.32363]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 943/943 [03:10<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [1.28994]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 943/943 [03:10<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [1.23076]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 943/943 [03:09<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [1.22349]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 943/943 [03:09<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [1.18287]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 943/943 [03:09<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [1.18113]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 943/943 [03:08<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [1.22742]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 943/943 [03:08<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [1.14433]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 943/943 [03:07<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [1.09651]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 943/943 [03:06<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [1.02045]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "infer_model = train(model, optimizer, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parameters() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m# Concatenate the two images together\u001b[39;00m\n\u001b[1;32m     18\u001b[0m concatenated \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((x0, x1), \u001b[39m0\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m output1, output2 \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mparameters(x0\u001b[39m.\u001b[39;49mcuda(), x1\u001b[39m.\u001b[39;49mcuda())\n\u001b[1;32m     21\u001b[0m euclidean_distance \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mpairwise_distance(output1, output2)\n\u001b[1;32m     22\u001b[0m imshow(torchvision\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mmake_grid(concatenated), \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDissimilarity: \u001b[39m\u001b[39m{\u001b[39;00meuclidean_distance\u001b[39m.\u001b[39mitem()\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: parameters() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# Locate the test dataset and load it into the SiameseNetworkDataset\n",
    "folder_dataset_test = datasets.ImageFolder(root=\"./output/val\")\n",
    "siamese_dataset = SiameseNetworkDataset(val[\"review_img_path\"].values, \n",
    "                                        val[\"product_img_path\"].values,\n",
    "                                        val[\"label\"].values,\n",
    "                                        transform=train_transform)\n",
    "test_dataloader = DataLoader(siamese_dataset, num_workers=0, batch_size=1, shuffle=True)\n",
    "\n",
    "# Grab one image that we are going to test\n",
    "dataiter = iter(test_dataloader)\n",
    "x0, _, _ = next(dataiter)\n",
    "\n",
    "for i in range(10):\n",
    "    # Iterate over 10 images and test them with the first image (x0)\n",
    "    _, x1, label2 = next(dataiter)\n",
    "\n",
    "    # Concatenate the two images together\n",
    "    concatenated = torch.cat((x0, x1), 0)\n",
    "    \n",
    "    output1, output2 = model.parameters(x0.cuda(), x1.cuda())\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    imshow(torchvision.utils.make_grid(concatenated), f'Dissimilarity: {euclidean_distance.item():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
